{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63c884e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schinavro/anaconda3/envs/simple/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from mlip.pes import PotentialNeuralNet\n",
    "from mlip.reann import REANN, compress_symbols\n",
    "\n",
    "species = [29]\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "lmax = 2\n",
    "nmax = 10\n",
    "loop = 3\n",
    "\n",
    "encode, decode, numbers = compress_symbols(species)\n",
    "species = list(set(numbers))\n",
    "reann = REANN(species, nmax=nmax, lmax=lmax, loop=loop)\n",
    "\n",
    "moduledict = nn.ModuleDict()\n",
    "desc = reann\n",
    "for spe in species:\n",
    "    moduledict[str(spe)] = nn.Sequential(\n",
    "        nn.Linear(desc.NO, int(desc.NO*1.3)),\n",
    "        nn.SiLU(),\n",
    "        nn.Linear(int(desc.NO*1.3), 1)\n",
    "    )\n",
    "moduledict = moduledict.double().to(device=device)\n",
    "    \n",
    "model = PotentialNeuralNet(desc, moduledict, species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e7fc4",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab28218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pymatgen.core import Structure\n",
    "from monty.serialization import loadfn\n",
    "location = \"../data/Cu/\"\n",
    "data = loadfn(location + 'training.json')\n",
    "\n",
    "#data[0]['structure'].cart_coords;\n",
    "#data[0]['structure'].lattice.matrix;\n",
    "#data[0]['outputs']['forces'];\n",
    "#data[0]['structure'].lattice.pbc;\n",
    "#data[0]['num_atoms']\n",
    "\n",
    "symbols = [[encode[n] for n in d['structure'].atomic_numbers] for d in data]\n",
    "positions = [d['structure'].cart_coords for d in data]\n",
    "energies = [d['outputs']['energy'] for d in data]\n",
    "cells = [d['structure'].lattice.matrix for d in data]\n",
    "gradients = [-np.array(d['outputs']['forces']) for d in data]\n",
    "\n",
    "crystalidx = [[idx] * data[idx]['num_atoms'] for idx in range(len(data))]\n",
    "pbcs = [np.array(d['structure'].lattice.pbc) for d in data]\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "631f30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomenclature\n",
    "# SPECG-CriP(symbols, positions, energies, cells, gradients, crystalindex, pbcs)\n",
    "\n",
    "import torch as tc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BPTypeDataset(Dataset):\n",
    "    \n",
    "    \"\"\"Behler Parrinello Type datasets\n",
    "    Indexing should be done in the unit of crystal, a set of atom used in one calculation. \n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        symbols: List\n",
    "        positions: List\n",
    "        energies: List\n",
    "        cells: List\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, symbols, positions, energies, cells, gradients, crystalidx, pbcs):\n",
    "        self.symbols = symbols\n",
    "        self.positions = positions\n",
    "        self.energies = energies\n",
    "        self.cells = cells\n",
    "        self.gradients = gradients\n",
    "        self.crystalidx = crystalidx\n",
    "        self.pbcs = pbcs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.energies)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.symbols[idx], self.positions[idx], self.energies[idx], self.cells[idx], self.gradients[idx], self.crystalidx[idx], self.pbcs[idx]\n",
    "\n",
    "    \n",
    "def concate(batch, device='cpu'):\n",
    "    cat = lambda x: tc.from_numpy(np.concatenate(x))\n",
    "    \n",
    "    symbols, positions, energies, cells, gradients, crystalidx, pbcs = [], [], [], [], [], [], []\n",
    "    for data in batch:\n",
    "        symbol, position, energy, cell, gradient, crystali, pbc = data\n",
    "        symbols.append(symbol)\n",
    "        positions.append(position)\n",
    "        energies.append(energy)\n",
    "        cells.append(cell[None])\n",
    "        gradients.append(gradient)\n",
    "        crystalidx.append(crystali)\n",
    "        pbcs.append(pbc[None])      \n",
    "\n",
    "    return (cat(symbols), cat(positions).to(device=device).requires_grad_(True), \n",
    "            energies, cat(cells).to(device=device).requires_grad_(True), \n",
    "            cat(gradients), cat(crystalidx), cat(pbcs))\n",
    "\n",
    "imgdataset = BPTypeDataset(symbols, positions, energies, cells, gradients, crystalidx, pbcs)\n",
    "dataloader = DataLoader(imgdataset, batch_size=100, shuffle=True, collate_fn=concate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "217c9195",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSEFLoss:\n",
    "    def __call__(self, predE, predF, y, dy):\n",
    "        N = len(y)\n",
    "        A = len(dy)\n",
    "        return tc.sum((y - predE) ** 2) / N,  tc.sum((predF - dy)**2) / A\n",
    "\n",
    "    \n",
    "class Normalizer(object):\n",
    "    \"\"\"Normalize a Tensor and restore it later. \"\"\"\n",
    "\n",
    "    def __init__(self, tensor, device='cpu'):\n",
    "        \"\"\"tensor is taken as a sample to calculate the mean and std\"\"\"\n",
    "        self.mean = tc.mean(tensor).to(device=device)\n",
    "        self.std = tc.std(tensor).to(device=device)\n",
    "\n",
    "    def norm(self, tensor):\n",
    "        return (tensor - self.mean) / self.std\n",
    "\n",
    "    def denorm(self, normed_tensor):\n",
    "        return normed_tensor * self.std + self.mean\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {'mean': self.mean,\n",
    "                'std': self.std}\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.mean = state_dict['mean']\n",
    "        self.std = state_dict['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22c9bbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2679.7673, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(13755.7717, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(85860.0291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(85860.0291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(65670.8525, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(8753.5878, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(846.9655, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(846.9655, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(13150.1512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(5781.6637, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(81813.4888, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor(81813.4888, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m normalizer \u001b[38;5;241m=\u001b[39m Normalizer(tc\u001b[38;5;241m.\u001b[39mtensor(imgdataset\u001b[38;5;241m.\u001b[39menergies)\u001b[38;5;241m.\u001b[39mdouble())\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5000\u001b[39m):\n\u001b[0;32m---> 30\u001b[0m     lossE, lossG \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMSEFLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss / MSE energy (eV)\u001b[39m\u001b[38;5;124m'\u001b[39m, lossE, t)\n\u001b[1;32m     34\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss / MSE grad (eV/A)\u001b[39m\u001b[38;5;124m'\u001b[39m, lossG, t)\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, normalizer, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m _, pred, predG \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcells\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrystalidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m lossE, lossG \u001b[38;5;241m=\u001b[39m loss_fn(pred, predG, normalizer\u001b[38;5;241m.\u001b[39mnorm(tc\u001b[38;5;241m.\u001b[39mtensor(energies)), gradients)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m lossE \u001b[38;5;241m+\u001b[39m lossG\n",
      "File \u001b[0;32m~/anaconda3/envs/simple/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/simple/lib/python3.8/site-packages/mlip/pes.py:66\u001b[0m, in \u001b[0;36mPotentialNeuralNet.forward\u001b[0;34m(self, symbols, positions, cells, crystalidx, pbcs, cutoff)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Descriptor calculation\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# NTA x 3 -> NTA x D\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcells\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrystalidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m positionsidx \u001b[38;5;241m=\u001b[39m tc\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(positions))\n\u001b[1;32m     69\u001b[0m energies, new_positionsidx \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/simple/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/simple/lib/python3.8/site-packages/mlip/reann.py:275\u001b[0m, in \u001b[0;36mREANN.forward\u001b[0;34m(self, symbols, positions, cells, crystalidx, pbcs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m    density ρ\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# Number of crystals, Number of total atoms\u001b[39;00m\n\u001b[1;32m    274\u001b[0m iidx, jidx, isym, jsym, disp, dist \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 275\u001b[0m     \u001b[43mget_neighbors_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcells\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrystalidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m NTA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(positions)\n\u001b[1;32m    278\u001b[0m dtype, device \u001b[38;5;241m=\u001b[39m positions\u001b[38;5;241m.\u001b[39mdtype, positions\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/anaconda3/envs/simple/lib/python3.8/site-packages/mlip/reann.py:151\u001b[0m, in \u001b[0;36mget_neighbors_info\u001b[0;34m(symbols, positions, cells, crystalidx, pbcs, cutoff)\u001b[0m\n\u001b[1;32m    149\u001b[0m pbc, cell \u001b[38;5;241m=\u001b[39m pbcs[c], cells[c]\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# NN, NN, NNx3, NN\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m idx, jdx, isy, jsy, dsp, dst \u001b[38;5;241m=\u001b[39m \u001b[43mget_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m iidx\u001b[38;5;241m.\u001b[39mappend(crystali[idx])\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# iidx.append(idx)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/simple/lib/python3.8/site-packages/mlip/reann.py:85\u001b[0m, in \u001b[0;36mget_nn\u001b[0;34m(symbols, positions, cell, pbc, cutoff, device)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# AxA\u001b[39;00m\n\u001b[1;32m     84\u001b[0m dist1 \u001b[38;5;241m=\u001b[39m tc\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(disp1, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m dist2 \u001b[38;5;241m=\u001b[39m \u001b[43mtc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisp2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# AxA\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n1 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m n2 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m n3 \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch as tc\n",
    "from torch.autograd import grad\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, normalizer, device='cpu'):\n",
    "    model.train()\n",
    "    for batch, _ in enumerate(dataloader):\n",
    "\n",
    "        symbols, positions, energies, cells, gradients, crystalidx, pbcs = _\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _, pred, predG = model(symbols, positions, cells, crystalidx, pbcs)\n",
    "        \n",
    "        lossE, lossG = loss_fn(pred, predG, normalizer.norm(tc.tensor(energies)), gradients)\n",
    "        loss = lossE + lossG\n",
    "        loss.requires_grad_(True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss)\n",
    "\n",
    "    return lossE, lossG\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='./20220727/copper_log3')\n",
    "\n",
    "normalizer = Normalizer(tc.tensor(imgdataset.energies).double())\n",
    "\n",
    "for t in range(5000):\n",
    "    lossE, lossG = train(dataloader, model, MSEFLoss(), \n",
    "                         tc.optim.Adam(model.parameters(), lr=1e-4), normalizer)\n",
    "\n",
    "    writer.add_scalar('Loss / MSE energy (eV)', lossE, t)\n",
    "    writer.add_scalar('Loss / MSE grad (eV/A)', lossG, t)\n",
    "    if t % 10 == 0:\n",
    "        tc.save(model.state_dict(), './20220727/weights_%d.pt' % t)\n",
    "    print(lossE + lossG)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af395762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.00490248\n",
      "1.88435672\n",
      "1.90425942\n",
      "2.10568615\n",
      "2.42064985\n",
      "2.41862855\n",
      "2.41162066\n",
      "2.02789275\n",
      "2.38261546\n",
      "3.35075651\n",
      "1.91148521\n",
      "2.11990854\n",
      "2.02127198\n",
      "2.05298301\n",
      "1.9428755\n",
      "2.66877109\n",
      "1.67471853\n",
      "2.37655509\n",
      "2.31506728\n",
      "1.97511936\n",
      "2.56171618\n",
      "1.79315339\n",
      "3.10943844\n",
      "4.07328121\n",
      "2.1872998\n",
      "2.56342477\n",
      "3.31252939\n",
      "2.29858133\n",
      "2.5937381\n",
      "2.07677032\n",
      "2.10531394\n",
      "2.17856415\n",
      "1.81384931\n",
      "1.98747497\n",
      "1.9025561\n",
      "2.33285158\n",
      "0.00654293\n",
      "0.02598919\n",
      "0.05001962\n",
      "0.03716252\n",
      "0.00985221\n",
      "0.15848953\n",
      "0.06256629\n",
      "0.02355748\n",
      "0.02758628\n",
      "0.03378437\n",
      "1.37066891\n",
      "2.0923333\n",
      "5.67867544\n",
      "2.7743811\n",
      "5.64298495\n",
      "1.54378861\n",
      "1.07237928\n",
      "1.24613588\n",
      "2.30511841\n",
      "6.18189068\n",
      "2.36663334\n",
      "1.04174789\n",
      "5.78603042\n",
      "2.52862694\n",
      "1.20674389\n",
      "6.34932396\n",
      "2.57476798\n",
      "5.92055725\n",
      "2.76558906\n",
      "6.12492511\n",
      "1.29420312\n",
      "5.73372392\n",
      "1.38538923\n",
      "5.74906068\n",
      "4.27844104\n",
      "2.28130515\n",
      "2.27994354\n",
      "1.6964395\n",
      "2.55221959\n",
      "4.74999497\n",
      "2.74798476\n",
      "1.85041649\n",
      "2.61005437\n",
      "1.24981979\n",
      "1.5877143\n",
      "5.51286462\n",
      "9.51405032\n",
      "2.6772384\n",
      "1.39114392\n",
      "1.67282552\n",
      "5.51579472\n",
      "1.71489834\n",
      "8.04241502\n",
      "4.60461193\n",
      "1.42695216\n",
      "2.52437342\n",
      "1.07472198\n",
      "5.72984181\n",
      "2.93761156\n",
      "2.0586927\n",
      "1.2888229\n",
      "5.51894653\n",
      "2.37726086\n",
      "1.36592219\n",
      "2.45903485\n",
      "5.9877982\n",
      "6.66569066\n",
      "1.45485674\n",
      "6.13975712\n",
      "2.5815329\n",
      "2.70819517\n",
      "5.38504095\n",
      "1.30623811\n",
      "2.68309377\n",
      "6.52706932\n",
      "2.6630039\n",
      "1.03660368\n",
      "6.22182591\n",
      "3.70878677\n",
      "1.15205098\n",
      "1.38721553\n",
      "1.2657404\n",
      "2.21683742\n",
      "7.78497803\n",
      "2.59679456\n",
      "1.141752\n",
      "1.27971745\n",
      "2.46873026\n",
      "2.81254028\n",
      "6.3482039\n",
      "1.22848838\n",
      "6.36907213\n",
      "5.79133003\n",
      "1.47796235\n",
      "2.27876433\n",
      "1.6822356\n",
      "6.75968229\n",
      "2.70915565\n",
      "1.18260825\n",
      "2.97551499\n",
      "6.35408912\n",
      "4.81801814\n",
      "1.05758533\n",
      "2.99220437\n",
      "2.38361694\n",
      "7.57170902\n",
      "2.67991973\n",
      "5.67307435\n",
      "1.89849303\n",
      "1.05893983\n",
      "2.24980433\n",
      "4.89096452\n",
      "1.30237464\n",
      "3.23448355\n",
      "3.32156019\n",
      "2.66732312\n",
      "1.15982909\n",
      "1.38982857\n",
      "-0.0\n",
      "-0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00049673\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "-0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.00068999\n",
      "0.00023493\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.00035464\n",
      "0.00061959\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "-0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.00032275\n",
      "-0.0\n",
      "-0.0\n",
      "0.0\n",
      "0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00098311\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.00109246\n",
      "0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "0.00037535\n",
      "0.0\n",
      "0.0\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "-0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "0.00027694\n",
      "0.00076705\n",
      "-0.0\n",
      "-0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00157365\n",
      "-0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.00089613\n",
      "0.00023476\n",
      "-0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.00178623\n",
      "0.0\n",
      "0.0\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "0.0\n",
      "-0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00089175\n",
      "-0.0\n",
      "-0.0\n",
      "0.0\n",
      "0.00019953\n",
      "-0.0\n",
      "-0.0\n",
      "-0.0\n",
      "-0.0\n",
      "0.00136071\n"
     ]
    }
   ],
   "source": [
    "for ma in imgdataset.gradients:\n",
    "    print(ma.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f4e567a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126a51b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple",
   "language": "python",
   "name": "simple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
